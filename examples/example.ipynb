{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import cv2\n",
    "# import matplotlib.pyplot as plt\n",
    "# %matplotlib qt\n",
    "\n",
    "#importing some useful packages\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import cv2\n",
    "import math\n",
    "from enum import Enum\n",
    "from collections import namedtuple\n",
    "import pickle\n",
    "%matplotlib inline\n",
    "\n",
    "# %matplotlib qt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "class File:\n",
    "    @staticmethod\n",
    "    def list_folder(folder_path):\n",
    "        return os.listdir(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageViewer:\n",
    "    @staticmethod\n",
    "    def display_image(cv_image):        \n",
    "        result = plt.imshow(cv_image.to_RGB().image_data)\n",
    "        \n",
    "        plt.colorbar()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        return result\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoadAs(Enum):\n",
    "    Grayscale = 1\n",
    "    ColorBGR = 2\n",
    "    ColorRGB = 3\n",
    "    ColorHSV = 4\n",
    "    ColorHSL = 5\n",
    "    \n",
    "class CvImage:\n",
    "    def __init__(self):\n",
    "        self.load_as = None\n",
    "        self.image_data = np.array([], dtype=np.int32)\n",
    "\n",
    "    @staticmethod\n",
    "    def create_black_image(width, height, channel_count = 3):\n",
    "        image_data = np.zeros((height, width, channel_count), np.uint8)\n",
    "\n",
    "        return CvImage.from_cv_image_data(image_data, LoadAs.ColorBGR)\n",
    "\n",
    "    @staticmethod\n",
    "    def load_from_file(filepath, load_as = LoadAs.ColorBGR):\n",
    "        instance = CvImage()\n",
    "        instance.load_as = load_as\n",
    "        if load_as == LoadAs.Grayscale:\n",
    "            instance.image_data = cv2.imread(filepath, cv2.IMREAD_GRAYSCALE)\n",
    "        else:\n",
    "            instance.image_data = cv2.imread(filepath)\n",
    "            \n",
    "        return instance\n",
    "    \n",
    "    @staticmethod\n",
    "    def from_cv_image_data(cv_image_data, load_as = LoadAs.ColorBGR):\n",
    "        \n",
    "#         if cv_image_data.shape[0] == 0:\n",
    "#             return None\n",
    "        \n",
    "        instance = CvImage()\n",
    "        instance.load_as = load_as\n",
    "        instance.image_data = cv_image_data\n",
    "        \n",
    "        return instance\n",
    "    \n",
    "    @staticmethod\n",
    "    def load_from_image_data(cv_image_data, load_as = LoadAs.ColorBGR):\n",
    "        return CvImage.from_cv_image_data(cv_image_data, load_as)\n",
    "\n",
    "    def _get_intensity_m(self, brightness_value):\n",
    "        intensitym = np.ones(self.image_data.shape, dtype=\"uint8\") * brightness_value\n",
    "        \n",
    "        return intensitym\n",
    "    \n",
    "    def darken(self, darken_value):\n",
    "        intensitym = self._get_intensity_m(darken_value)\n",
    "        darkened_image_data = cv2.subtract(self.image_data, intensitym)\n",
    "        \n",
    "        return CvImage.load_from_image_data(darkened_image_data, self.load_as)\n",
    "    \n",
    "    def brighten(self, darken_value):\n",
    "        intensitym = self._get_intensity_m(darken_value)\n",
    "        darkened_image_data = cv2.add(self.image_data, intensitym)\n",
    "        \n",
    "        return CvImage.load_from_image_data(darkened_image_data, self.load_as)\n",
    "\n",
    "    def height(self):\n",
    "#         if self.image_data.shape[0] == 0:\n",
    "#             return 0\n",
    "        height, width = self.image_data.shape[:2]\n",
    "        \n",
    "        return height\n",
    "    \n",
    "    def width(self):\n",
    "#         if self.image_data.shape[0] == 0:\n",
    "#             return 0\n",
    "        height, width = self.image_data.shape[:2]\n",
    "        \n",
    "        return width\n",
    "        \n",
    "\n",
    "    def channel_count(self):\n",
    "#         if self.image_data.shape[0] == 0:\n",
    "#             return 0\n",
    "        return self.image_data.shape[2]\n",
    "    \n",
    "    def to_grayscale(self):\n",
    "#         if self.image_data.shape[0] == 0:\n",
    "#             return None        \n",
    "        grayscale_image = cv2.cvtColor(self.image_data, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        return CvImage.from_cv_image_data(grayscale_image, LoadAs.Grayscale)\n",
    "    \n",
    "\n",
    "    def mask_and(self, other_image):\n",
    "        result = cv2.bitwise_and(self.image_data, other_image.image_data)\n",
    "        \n",
    "        return CvImage.load_from_image_data(result, self.load_as)\n",
    "    \n",
    "    def mask_or(self, other_image):\n",
    "        result = cv2.bitwise_or(self.image_data, other_image.image_data)\n",
    "        \n",
    "        return CvImage.load_from_image_data(result, self.load_as)\n",
    "\n",
    "    def mask_xor(self, other_image):\n",
    "        result = cv2.bitwise_xor(self.image_data, other_image.image_data)\n",
    "        \n",
    "        return CvImage.load_from_image_data(result, self.load_as)\n",
    "\n",
    "    def mask_not(self):\n",
    "        result = cv2.bitwise_not(self.image_data)\n",
    "        \n",
    "        return CvImage.load_from_image_data(result, self.load_as)\n",
    "    \n",
    "    def to_HSV(self):\n",
    "        hsv = cv2.cvtColor(self.image_data, cv2.COLOR_RGB2HSV)\n",
    "        \n",
    "        return CvImage.load_from_image_data(hsv, LoadAs.ColorHSV)\n",
    "\n",
    "    def to_HSL(self):\n",
    "        hsv = cv2.cvtColor(self.image_data, cv2.COLOR_RGB2HLS)\n",
    "        \n",
    "        return CvImage.load_from_image_data(hsv, LoadAs.ColorHSL)\n",
    "    \n",
    "    def to_RGB(self):\n",
    "        if self.load_as == LoadAs.Grayscale:\n",
    "            rgb_image = cv2.cvtColor(self.image_data, cv2.COLOR_GRAY2RGB)\n",
    "            \n",
    "            return CvImage.load_from_image_data(rgb_image, LoadAs.ColorRGB)\n",
    "        else:\n",
    "            rgb_image = cv2.cvtColor(self.image_data, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            return CvImage.load_from_image_data(rgb_image, LoadAs.ColorRGB)\n",
    "    \n",
    "    def gaussian_blur(self, kernel_size = 5):\n",
    "        blurred = cv2.GaussianBlur(self.image_data, (kernel_size, kernel_size), 0)\n",
    "        \n",
    "        return CvImage.load_from_image_data(blurred, self.load_as);\n",
    "    \n",
    "    def threshold(self, black_threshold, other_color, ttype):\n",
    "        ret, result = cv2.threshold(self.image_data, black_threshold, other_color, ttype)\n",
    "        \n",
    "        return CvImage.load_from_image_data(result, self.load_as)\n",
    "    \n",
    "    def threshold_binary(self, black_threshold, other_color):\n",
    "        return self.threshold(black_threshold, other_color, cv2.THRESH_BINARY)\n",
    "        \n",
    "    def threshold_binary_inverse(self, black_threshold, other_color):\n",
    "        return self.threshold(black_threshold, other_color, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "    def threshold_truncate(self, black_threshold, other_color):\n",
    "        return self.threshold(black_threshold, other_color, cv2.THRESH_TRUNC)\n",
    "    \n",
    "    def threshold_to_zero(self, black_threshold, other_color):\n",
    "        return self.threshold(black_threshold, other_color, cv2.THRESH_TOZERO)\n",
    "    \n",
    "    def canny(self, low_threshold = 50, high_threshold = 150, aperture_size = 3):\n",
    "        cannied = cv2.Canny(self.image_data, low_threshold, high_threshold, aperture_size)\n",
    "        \n",
    "        return CvImage.load_from_image_data(cannied, self.load_as)    \n",
    "        \n",
    "                \n",
    "    \n",
    "    def filter_inrange(self, lower_value, upper_value):\n",
    "        filtered = cv2.inRange(self.image_data, lower_value, upper_value)\n",
    "        \n",
    "        return CvImage.load_from_image_data(filtered, self.load_as)\n",
    "    \n",
    "    def find_chessboard_corners(self, corners_x, corners_y):\n",
    "        ret, corners = cv2.findChessboardCorners(self.image_data, (corners_x, corners_y), None)\n",
    "        \n",
    "        if ret == True:\n",
    "            return corners\n",
    "        else:\n",
    "            return []\n",
    "    \n",
    "    def draw_chessboard_corners(self, corners_x, corners_y):\n",
    "        gray = self.to_grayscale()\n",
    "        corners = gray.find_chessboard_corners(corners_x, corners_y)\n",
    "\n",
    "        # If found, draw corners\n",
    "        if len(corners) > 0:\n",
    "            # Draw and display the corners\n",
    "            copied_image = np.copy(self.image_data)\n",
    "            cv2.drawChessboardCorners(copied_image, (corners_x, corners_y), corners, True)\n",
    "        else:\n",
    "            print(\"Failed top find chessboard corners\")\n",
    "            return self\n",
    "        \n",
    "        return CvImage.load_from_image_data(copied_image, self.load_as)\n",
    "    \n",
    "    def undistort(self, camera_calibration_result):\n",
    "        undistorted = cv2.undistort(self.image_data, camera_calibration_result.calibration_matrix, camera_calibration_result.calibration_distance, None, camera_calibration_result.new_camera_matrix)\n",
    "        \n",
    "        return CvImage.load_from_image_data(undistorted, self.load_as)\n",
    "            \n",
    "    def unwarp(self, src, dst):\n",
    "        h,w = self.image_data.shape[:2]\n",
    "        M = cv2.getPerspectiveTransform(src, dst)\n",
    "        Minv = cv2.getPerspectiveTransform(dst, src)\n",
    "        warped = cv2.warpPerspective(img, M, (w,h), flags=cv2.INTER_LINEAR)\n",
    "        \n",
    "        return CvImage.load_from_image_data(warped)\n",
    "#         return warped, M, Minv\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "CameraCalibrationResult = namedtuple(\"CameraCalibrationResult\", \"calibration_matrix calibration_distance new_camera_matrix\")\n",
    "\n",
    "class Camera:\n",
    "    def __init__(self):\n",
    "        self.calibration_matrix = None\n",
    "        self.calibration_distance = -1\n",
    "        self.new_camera_matrix = None\n",
    "        \n",
    "    def find_correct_corners(self, calibration_image_files):\n",
    "        index = 0\n",
    "        corners_hash = {}\n",
    "        for calibration_image_file in calibration_image_files:\n",
    "            cvimage = CvImage.load_from_file(calibration_image_file)\n",
    "            gray = cvimage.to_grayscale()\n",
    "            corners_found = False\n",
    "            for i in range(10, 2, -1):\n",
    "                for j in range(7, 2, -1):\n",
    "                    print('searching with x:' + str(i) + ', y:' + str(j) )\n",
    "                    corners = gray.find_chessboard_corners(i, j)\n",
    "                    if len(corners) > 0:\n",
    "                        corners_hash[index] = (i, j)\n",
    "                        corners_found = True\n",
    "                        break\n",
    "                if corners_found: \n",
    "                    break                \n",
    "            index += 1\n",
    "            \n",
    "        return corners_hash\n",
    "        \n",
    "    def calibrate(self, calibration_image_files, points_x, points_y):        \n",
    "        objpoints = []\n",
    "        imgpoints = []\n",
    "        \n",
    "        criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "\n",
    "        \n",
    "        index = 0\n",
    "        for calibration_image_file in calibration_image_files:            \n",
    "#             points_x = 8 #corners_hash[index][0]\n",
    "#             points_y = 6 #corners_hash[index][1]\n",
    "\n",
    "            objp = np.zeros((points_x * points_y, 3), np.float32)\n",
    "            objp[:,:2] = np.mgrid[0:points_x,0:points_y].T.reshape(-1, 2)\n",
    "            \n",
    "            calibration_image = CvImage.load_from_file(calibration_image_file, LoadAs.Grayscale)\n",
    "            \n",
    "            chessboard_corners = calibration_image.find_chessboard_corners(points_x, points_y)\n",
    "            if len(chessboard_corners) > 0:\n",
    "                corners2 = cv2.cornerSubPix(calibration_image.image_data,chessboard_corners,(11,11),(-1,-1),criteria)\n",
    "                                \n",
    "                imgpoints.append(corners2)\n",
    "                objpoints.append(objp)\n",
    "            else:\n",
    "                print('Not found for index:' + str(index))\n",
    "                \n",
    "            index += 1\n",
    "            \n",
    "            \n",
    "        if self.calibration_distance == -1:      \n",
    "            calibration_image = CvImage.load_from_file(calibration_image_file)\n",
    "            image_dimension = (img.shape[1], img.shape[0])\n",
    "            ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, image_dimension, None, None)\n",
    "            self.calibration_matrix = mtx\n",
    "            self.calibration_distance = dist\n",
    "            \n",
    "        \n",
    "        return CameraCalibrationResult(self.calibration_matrix, self.calibration_distance, self.calibration_matrix)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Viewport:    \n",
    "    \n",
    "    @staticmethod\n",
    "    def y(image):\n",
    "        height, width = image.shape[:2]\n",
    "        viewport_y = math.floor(height / 2) + 50\n",
    "\n",
    "        if height != 720:\n",
    "            viewport_y += 50\n",
    "        else:\n",
    "            viewport_y += 100\n",
    "        \n",
    "        return viewport_y\n",
    "    \n",
    "    @staticmethod\n",
    "    def whole_area_polygon(image):\n",
    "        height, width = image.shape[:2]\n",
    "        mid_of_viewport_x = math.floor(width / 2)\n",
    "        viewport_y = math.floor(height / 2) #+ 50 + 90\n",
    "        \n",
    "        if height != 720:\n",
    "            viewport_y += 50\n",
    "        else:\n",
    "            viewport_y += 100\n",
    "        \n",
    "        viewport_right_x = mid_of_viewport_x + 90\n",
    "        viewport_left_x = mid_of_viewport_x - 90\n",
    "        return Polygon.create_from_array(np.array([(viewport_left_x, viewport_y), (0, height), (width, height), (viewport_right_x, viewport_y)]))         \n",
    "        \n",
    "    @staticmethod\n",
    "    def whole_area_to_perspective_transform_source(image):\n",
    "        viewport_arr = Viewport.whole_area_polygon(image.image_data).arr\n",
    "        src = np.float32([viewport_arr[0],\n",
    "                          viewport_arr[3],\n",
    "                          viewport_arr[1],\n",
    "                          viewport_arr[2]])\n",
    "        \n",
    "        return src\n",
    "    \n",
    "    @staticmethod\n",
    "    def whole_area_to_perspective_transform_target(image):\n",
    "        height, width = image.image_data.shape[:2]\n",
    "        dst = np.float32([(450,0),\n",
    "                          (width-450,0),\n",
    "                          (450,height),\n",
    "                          (width-450,height)])\n",
    "        \n",
    "        return dst\n",
    "        \n",
    "        \n",
    "    \n",
    "    @staticmethod\n",
    "    def right_area_polygon(image):\n",
    "        height, width = image.shape[:2]\n",
    "        mid_of_viewport_x = math.floor(width / 2)\n",
    "        viewport_y = math.floor(height / 2) #+ 50 + 90\n",
    "\n",
    "        if height != 720:\n",
    "            viewport_y += 50\n",
    "        else:\n",
    "            viewport_y += 100\n",
    "        \n",
    "        viewport_right_x = mid_of_viewport_x + 30\n",
    "        return Polygon.create_from_array(np.array([(mid_of_viewport_x + 1, viewport_y), (mid_of_viewport_x + 1, height), (width, height), (viewport_right_x, viewport_y)]))         \n",
    "    \n",
    "    @staticmethod\n",
    "    def left_area_polygon(image):\n",
    "        height, width = image.shape[:2]\n",
    "        mid_of_viewport_x = math.floor(width / 2)\n",
    "        viewport_y = math.floor(height / 2) #+ 50 + 90\n",
    "        \n",
    "        if height != 720:\n",
    "            viewport_y += 50\n",
    "        else:\n",
    "            viewport_y += 100\n",
    "        \n",
    "        viewport_left_x = mid_of_viewport_x - 30\n",
    "        return Polygon.create_from_array(np.array([(viewport_left_x, viewport_y), (0,height), (mid_of_viewport_x, height), (mid_of_viewport_x, viewport_y)]))         \n",
    "    \n",
    "    @staticmethod\n",
    "    def get_mask_image(target_image):\n",
    "        viewport_image = CvImage.create_black_image(target_image.width(), target_image.height(), target_image.channel_count())\n",
    "\n",
    "        vertices = Viewport.whole_area_polygon(target_image.image_data)\n",
    "        PolygonPlotter.draw_to(viewport_image, vertices.arr)\n",
    "        \n",
    "        return viewport_image\n",
    "        \n",
    "    \n",
    "class Polygon:\n",
    "    @staticmethod\n",
    "    def create_from_array(arr):\n",
    "        poly = Polygon(arr)\n",
    "        \n",
    "        return poly\n",
    "        \n",
    "    def __init__(self, arr):\n",
    "        self.arr = arr\n",
    "        \n",
    "    def is_point_inside(self, point_tuple):\n",
    "        result = cv2.pointPolygonTest(self.arr, point_tuple, False)         \n",
    "        \n",
    "        return (result >= 0)\n",
    "        \n",
    "    \n",
    "class Line:\n",
    "    def __init__(self, x1, y1, x2, y2):\n",
    "        self.x1 = x1\n",
    "        self.y1 = y1\n",
    "        self.x2 = x2\n",
    "        self.y2 = y2\n",
    "        \n",
    "    @staticmethod\n",
    "    def create_from_array(arr):\n",
    "        x1, y1, x2, y2 = arr[0]\n",
    "        new_line = Line(x1, y1, x2, y2)\n",
    "        \n",
    "        return new_line\n",
    "    \n",
    "    \n",
    "    def abs_dx(self):\n",
    "        return abs(self.dx())\n",
    "        \n",
    "    def abs_dy(self):\n",
    "        return abs(self.dy())\n",
    "\n",
    "    def dx(self):\n",
    "        return self.x1 - self.x2\n",
    "        \n",
    "    def dy(self):\n",
    "        return self.y1 - self.y2\n",
    "    \n",
    "    def slope(self):\n",
    "        return self.dy() / self.dx()\n",
    "    \n",
    "    def is_inside(self, polygon):\n",
    "        return (polygon.is_point_inside((self.x1, self.y1)) and polygon.is_point_inside((self.x2, self.y2)))\n",
    "        \n",
    "    \n",
    "class LinePlotter:\n",
    "    @staticmethod\n",
    "    def draw_to(target_image, point1, point2, thickness = 4, bgr_color = (100, 255, 0)):\n",
    "        cv2.line(target_image.image_data, point1, point2, bgr_color, thickness)\n",
    "        \n",
    "class CirclePlotter:\n",
    "    @staticmethod\n",
    "    def draw_to(target_image, center_point, radius, bgr_color = (100, 255, 0), solid_color = -1):\n",
    "        cv2.circle(target_image.image_data, center_point, radius, bgr_color, solid_color)\n",
    "        \n",
    "class RectanglePlotter:\n",
    "    @staticmethod\n",
    "    def draw_to(target_image, left_point, right_point, bgr_color, solid_color = -2):\n",
    "        cv2.rectangle(target_image.image_data, left_point, right_point, bgr_color, solid_color)\n",
    "    \n",
    "class PolygonPlotter:\n",
    "    @staticmethod\n",
    "    def draw_to(target_image, vertices, color_value = (255, 255, 255)):\n",
    "        adapted_vertices = np.array([vertices], dtype=np.int32)\n",
    "        cv2.fillPoly(target_image.image_data, adapted_vertices, color_value)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fd5b8479f10>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvimage = CvImage.load_from_file('../test_images/calibration_test.png')\n",
    "\n",
    "ImageViewer.display_image(cvimage.draw_chessboard_corners(8, 6))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not found for index:0\n",
      "Not found for index:1\n",
      "Not found for index:6\n",
      "CameraCalibrationResult(calibration_matrix=array([[1.15693957e+03, 0.00000000e+00, 6.65948026e+02],\n",
      "       [0.00000000e+00, 1.15213792e+03, 3.88785776e+02],\n",
      "       [0.00000000e+00, 0.00000000e+00, 1.00000000e+00]]), calibration_distance=array([[-2.37636474e-01, -8.54104018e-02, -7.90992506e-04,\n",
      "        -1.15920533e-04,  1.05737433e-01]]), new_camera_matrix=array([[1.15693957e+03, 0.00000000e+00, 6.65948026e+02],\n",
      "       [0.00000000e+00, 1.15213792e+03, 3.88785776e+02],\n",
      "       [0.00000000e+00, 0.00000000e+00, 1.00000000e+00]]))\n"
     ]
    }
   ],
   "source": [
    "calibration_image_files = File.list_folder('../camera_cal/')\n",
    "\n",
    "calibration_image_files = list(map(lambda x: '../camera_cal/' + x, calibration_image_files))\n",
    "# calibration_image_files.append('../test_images/calibration_test.png')\n",
    "\n",
    "corners_hash = {0: (7, 6), 1: (7, 4), 2: (9, 6), 3: (9, 6), 4: (9, 6), 5: (9, 6), 6: (9, 5), 7: (9, 6), 8: (9, 6), 9: (9, 6), 10: (9, 6), 11: (9, 6), 12: (9, 6), 13: (9, 6), 14: (9, 6), 15: (9, 6), 16: (9, 6), 17: (9, 6), 18: (9, 6), 19: (9, 6), 20:(8,6)}\n",
    "\n",
    "# index = 4\n",
    "# cvimage = CvImage.load_from_file(calibration_image_files[index])\n",
    "\n",
    "# ImageViewer.display_image(cvimage.draw_chessboard_corners(corners_hash[index][0], corners_hash[index][1]))\n",
    "\n",
    "\n",
    "camera = Camera()\n",
    "\n",
    "calibration_result = camera.calibrate(calibration_image_files, 9, 6)\n",
    "\n",
    "print(calibration_result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "calibration_matrix=np.array([[1.15693957e+03, 0.00000000e+00, 6.65948026e+02],\n",
    "       [0.00000000e+00, 1.15213792e+03, 3.88785776e+02],\n",
    "       [0.00000000e+00, 0.00000000e+00, 1.00000000e+00]])\n",
    "calibration_distance=np.array([[-2.37636474e-01, -8.54104018e-02, -7.90992506e-04,\n",
    "        -1.15920533e-04,  1.05737433e-01]])\n",
    "\n",
    "calibration_result = CameraCalibrationResult(calibration_matrix, calibration_distance, calibration_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fc4bf3f36a0>"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distorted_image = CvImage.load_from_file('../camera_cal/calibration2.jpg')\n",
    "\n",
    "undistorted_image = distorted_image.undistort(calibration_result)\n",
    "\n",
    "ImageViewer.display_image(undistorted_image)\n",
    "# ImageViewer.display_image(distorted_image.draw_chessboard_corners(8,6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Lane Finding Project\n",
    "\n",
    "The goals / steps of this project are the following:\n",
    "\n",
    "* Compute the camera calibration matrix and distortion coefficients given a set of chessboard images.\n",
    "* Apply a distortion correction to raw images.\n",
    "* Use color transforms, gradients, etc., to create a thresholded binary image.\n",
    "* Apply a perspective transform to rectify binary image (\"birds-eye view\").\n",
    "* Detect lane pixels and fit to find the lane boundary.\n",
    "* Determine the curvature of the lane and vehicle position with respect to center.\n",
    "* Warp the detected lane boundaries back onto the original image.\n",
    "* Output visual display of the lane boundaries and numerical estimation of lane curvature and vehicle position.\n",
    "\n",
    "---\n",
    "## First, I'll compute the camera calibration using chessboard images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...\n"
     ]
    }
   ],
   "source": [
    "# Test undistortion on an image\n",
    "img = cv2.imread('../camera_cal/calibration1.jpg')\n",
    "img = cv2.imread('../test_images/calibration_test.png')\n",
    "img_size = (img.shape[1], img.shape[0])\n",
    "\n",
    "# Do camera calibration given object points and image points\n",
    "ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, img_size,None,None)\n",
    "# dst = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "dst = cv2.undistort(img, calibration_result.calibration_matrix, calibration_result.calibration_distance, None, calibration_result.calibration_matrix)\n",
    "\n",
    "# Save the camera calibration result for later use (we won't worry about rvecs / tvecs)\n",
    "dist_pickle = {}\n",
    "dist_pickle[\"mtx\"] = mtx\n",
    "dist_pickle[\"dist\"] = dist\n",
    "# pickle.dump( dist_pickle, open( \"calibration.p\", \"wb\" ) )\n",
    "#dst = cv2.cvtColor(dst, cv2.COLOR_BGR2RGB)\n",
    "# Visualize undistortion\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,10))\n",
    "f.subplots_adjust(hspace = .2, wspace=.05)\n",
    "ax1.imshow(img)\n",
    "ax1.set_title('Original Image', fontsize=30)\n",
    "ax2.imshow(dst)\n",
    "ax2.set_title('Undistorted Image', fontsize=30)\n",
    "print('...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fc464db8940>"
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv2.imread('../test_images/test2.jpg')\n",
    "\n",
    "\n",
    "# viewport_arr = Viewport.whole_area_polygon(img).arr\n",
    "\n",
    "src = Viewport.whole_area_to_perspective_transform_source(img)\n",
    "dst = Viewport.whole_area_to_perspective_transform_target(img)\n",
    "\n",
    "exampleImg_unwarp = cvimage.load_from_image_data(img).unwarp(src, dst)\n",
    "\n",
    "ImageViewer.display_image(exampleImg_unwarp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 1683\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.5.1) /private/var/folders/nz/vv4_9tw56nv9k3tkvyszvwg80000gn/T/pip-req-build-yaf6rry6/opencv/modules/core/src/array.cpp:3229: error: (-215:Assertion failed) cn <= 4 in function 'scalarToRawData'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-443-e026e8dd9c29>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m \u001b[0mout_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_polynomial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbinary_warped\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-443-e026e8dd9c29>\u001b[0m in \u001b[0;36mfit_polynomial\u001b[0;34m(binary_warped)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfit_polynomial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbinary_warped\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;31m# Find our lane pixels first\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m     \u001b[0mleftx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlefty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrightx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrighty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_lane_pixels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbinary_warped\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;31m#     # Fit a second order polynomial to each using `np.polyfit`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-443-e026e8dd9c29>\u001b[0m in \u001b[0;36mfind_lane_pixels\u001b[0;34m(binary_warped)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;31m# Draw the windows on the visualization image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         cv2.rectangle(out_img,(win_xleft_low,win_y_low),\n\u001b[0m\u001b[1;32m     58\u001b[0m         (win_xleft_high,win_y_high),(0,255,0), 2) \n\u001b[1;32m     59\u001b[0m         cv2.rectangle(out_img,(win_xright_low,win_y_low),\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.5.1) /private/var/folders/nz/vv4_9tw56nv9k3tkvyszvwg80000gn/T/pip-req-build-yaf6rry6/opencv/modules/core/src/array.cpp:3229: error: (-215:Assertion failed) cn <= 4 in function 'scalarToRawData'\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "# Load our image\n",
    "binary_warped = mpimg.imread('../test_images/s1.png')\n",
    "\n",
    "def find_lane_pixels(binary_warped):\n",
    "    # Take a histogram of the bottom half of the image\n",
    "    histogram = np.sum(binary_warped[binary_warped.shape[0]//2:,:], axis=0)\n",
    "    # Create an output image to draw on and visualize the result\n",
    "    out_img = np.dstack((binary_warped, binary_warped, binary_warped))\n",
    "    # Find the peak of the left and right halves of the histogram\n",
    "    # These will be the starting point for the left and right lines\n",
    "    midpoint = np.int(histogram.shape[0]//2)\n",
    "    leftx_base = np.argmax(histogram[:midpoint])\n",
    "    rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "\n",
    "    \n",
    "    print(leftx_base, rightx_base)\n",
    "    \n",
    "    # HYPERPARAMETERS\n",
    "    # Choose the number of sliding windows\n",
    "    nwindows = 9\n",
    "    # Set the width of the windows +/- margin\n",
    "    margin = 100\n",
    "    # Set minimum number of pixels found to recenter window\n",
    "    minpix = 50\n",
    "\n",
    "    # Set height of windows - based on nwindows above and image shape\n",
    "    window_height = np.int(binary_warped.shape[0]//nwindows)\n",
    "\n",
    "    # Identify the x and y positions of all nonzero pixels in the image\n",
    "    nonzero = binary_warped.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    # Current positions to be updated later for each window in nwindows\n",
    "    leftx_current = leftx_base\n",
    "    rightx_current = rightx_base\n",
    "\n",
    "    # Create empty lists to receive left and right lane pixel indices\n",
    "    left_lane_inds = []\n",
    "    right_lane_inds = []\n",
    "\n",
    "    # Step through the windows one by one\n",
    "    for window in range(nwindows):\n",
    "        # Identify window boundaries in x and y (and right and left)\n",
    "        win_y_low = binary_warped.shape[0] - (window+1)*window_height\n",
    "        win_y_high = binary_warped.shape[0] - window*window_height\n",
    "        win_xleft_low = leftx_current - margin\n",
    "        win_xleft_high = leftx_current + margin\n",
    "        win_xright_low = rightx_current - margin\n",
    "        win_xright_high = rightx_current + margin\n",
    "        \n",
    "        # Draw the windows on the visualization image\n",
    "        cv2.rectangle(out_img,(win_xleft_low,win_y_low),\n",
    "        (win_xleft_high,win_y_high),(0,255,0), 2) \n",
    "        cv2.rectangle(out_img,(win_xright_low,win_y_low),\n",
    "        (win_xright_high,win_y_high),(0,255,0), 2) \n",
    "        \n",
    "#         # Identify the nonzero pixels in x and y within the window #\n",
    "#         good_left_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & \n",
    "#         (nonzerox >= win_xleft_low) &  (nonzerox < win_xleft_high)).nonzero()[0]\n",
    "#         good_right_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & \n",
    "#         (nonzerox >= win_xright_low) &  (nonzerox < win_xright_high)).nonzero()[0]\n",
    "        \n",
    "#         # Append these indices to the lists\n",
    "#         left_lane_inds.append(good_left_inds)\n",
    "#         right_lane_inds.append(good_right_inds)\n",
    "        \n",
    "#         # If you found > minpix pixels, recenter next window on their mean position\n",
    "#         if len(good_left_inds) > minpix:\n",
    "#             leftx_current = np.int(np.mean(nonzerox[good_left_inds]))\n",
    "#         if len(good_right_inds) > minpix:        \n",
    "#             rightx_current = np.int(np.mean(nonzerox[good_right_inds]))\n",
    "\n",
    "    # Concatenate the arrays of indices (previously was a list of lists of pixels)\n",
    "#     try:\n",
    "#         left_lane_inds = np.concatenate(left_lane_inds)\n",
    "#         right_lane_inds = np.concatenate(right_lane_inds)\n",
    "#     except ValueError:\n",
    "#         # Avoids an error if the above is not implemented fully\n",
    "#         pass\n",
    "\n",
    "#     # Extract left and right line pixel positions\n",
    "#     leftx = nonzerox[left_lane_inds]\n",
    "#     lefty = nonzeroy[left_lane_inds] \n",
    "#     rightx = nonzerox[right_lane_inds]\n",
    "#     righty = nonzeroy[right_lane_inds]\n",
    "\n",
    "    return leftx, lefty, rightx, righty, out_img\n",
    "\n",
    "\n",
    "def fit_polynomial(binary_warped):\n",
    "    # Find our lane pixels first\n",
    "    leftx, lefty, rightx, righty, out_img = find_lane_pixels(binary_warped)\n",
    "\n",
    "#     # Fit a second order polynomial to each using `np.polyfit`\n",
    "#     left_fit = np.polyfit(lefty, leftx, 2)\n",
    "#     right_fit = np.polyfit(righty, rightx, 2)\n",
    "\n",
    "#     # Generate x and y values for plotting\n",
    "#     ploty = np.linspace(0, binary_warped.shape[0]-1, binary_warped.shape[0] )\n",
    "#     try:\n",
    "#         left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "#         right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "#     except TypeError:\n",
    "#         # Avoids an error if `left` and `right_fit` are still none or incorrect\n",
    "#         print('The function failed to fit a line!')\n",
    "#         left_fitx = 1*ploty**2 + 1*ploty\n",
    "#         right_fitx = 1*ploty**2 + 1*ploty\n",
    "\n",
    "#     ## Visualization ##\n",
    "#     # Colors in the left and right lane regions\n",
    "#     out_img[lefty, leftx] = [255, 0, 0]\n",
    "#     out_img[righty, rightx] = [0, 0, 255]\n",
    "\n",
    "#     # Plots the left and right polynomials on the lane lines\n",
    "#     plt.plot(left_fitx, ploty, color='yellow')\n",
    "#     plt.plot(right_fitx, ploty, color='yellow')\n",
    "\n",
    "    return out_img\n",
    "\n",
    "\n",
    "out_img = fit_polynomial(binary_warped)\n",
    "\n",
    "plt.imshow(out_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fc461a424c0>,\n",
       " <matplotlib.lines.Line2D at 0x7fc461a42520>,\n",
       " <matplotlib.lines.Line2D at 0x7fc461a425e0>]"
      ]
     },
     "execution_count": 407,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv2.imread('../test_images/s1.png')\n",
    "\n",
    "def hist(img):\n",
    "    # Grab only the bottom half of the image\n",
    "    # Lane lines are likely to be mostly vertical nearest to the car\n",
    "    bottom_half = img[img.shape[0]//2:,:]\n",
    "\n",
    "    # Sum across image pixels vertically - make sure to set an `axis`\n",
    "    # i.e. the highest areas of vertical lines should be larger values\n",
    "    histogram = np.sum(bottom_half, axis=0)\n",
    "    \n",
    "    return histogram\n",
    "\n",
    "histogram = hist(img)\n",
    "\n",
    "# Visualize the resulting histogram\n",
    "plt.plot(histogram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "\n",
    "calibration_matrix=np.array([[1.15693957e+03, 0.00000000e+00, 6.65948026e+02],\n",
    "       [0.00000000e+00, 1.15213792e+03, 3.88785776e+02],\n",
    "       [0.00000000e+00, 0.00000000e+00, 1.00000000e+00]])\n",
    "calibration_distance=np.array([[-2.37636474e-01, -8.54104018e-02, -7.90992506e-04,\n",
    "        -1.15920533e-04,  1.05737433e-01]])\n",
    "\n",
    "calibration_result = CameraCalibrationResult(calibration_matrix, calibration_distance, calibration_matrix)\n",
    "\n",
    "def process_image(image):\n",
    "    distorted_image = CvImage.load_from_image_data(image)\n",
    "    undistorted_image = distorted_image.undistort(calibration_result)\n",
    "        \n",
    "\n",
    "    yellow_mask = undistorted_image.to_HSL().filter_inrange(np.array([0, 0, 75]),np.array([255, 255, 255]))\n",
    "    white_mask = undistorted_image.to_HSL().filter_inrange(np.array([0, 211, 0]),np.array([255, 255, 255]))\n",
    "\n",
    "\n",
    "    dark_image = yellow_mask.mask_or(white_mask).to_RGB().mask_and(Viewport.get_mask_image(undistorted_image))\n",
    "\n",
    "    src = Viewport.whole_area_to_perspective_transform_source(dark_image)\n",
    "    dst = Viewport.whole_area_to_perspective_transform_target(dark_image)\n",
    "\n",
    "    exampleImg_unwarp = dark_image.unwarp(src, dst)\n",
    "    \n",
    "    \n",
    "    return dark_image.image_data\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video ../test_videos_output/project_video.mp4.\n",
      "Moviepy - Writing video ../test_videos_output/project_video.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready ../test_videos_output/project_video.mp4\n",
      "CPU times: user 47.1 s, sys: 6.07 s, total: 53.1 s\n",
      "Wall time: 24.6 s\n"
     ]
    }
   ],
   "source": [
    "white_output = '../test_videos_output/project_video.mp4'\n",
    "## To speed up the testing process you may want to try your pipeline on a shorter subclip of the video\n",
    "## To do so add .subclip(start_second,end_second) to the end of the line below\n",
    "## Where start_second and end_second are integer values representing the start and end of the subclip\n",
    "## You may also uncomment the following line for a subclip of the first 5 seconds\n",
    "##clip1 = VideoFileClip(\"test_videos/solidWhiteRight.mp4\").subclip(0,5)\n",
    "clip1 = VideoFileClip(\"../project_video.mp4\")\n",
    "white_clip = clip1.fl_image(process_image) #NOTE: this function expects color images!!\n",
    "%time white_clip.write_videofile(white_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"../test_videos_output/project_video.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 404,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(white_output))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
